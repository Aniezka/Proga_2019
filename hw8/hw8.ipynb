{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rm0hokW1ctGm"
   },
   "source": [
    "## Домашнее задание 8 (бонусное). Обработка текстов. \n",
    "Дедлайн: 24.06.2020 23:59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbzklKqIVf-h"
   },
   "source": [
    "Ваша задача - определить тональность твита (0 - отрицательная, 4 - положительная) по его тексту.       \n",
    "Ваша модель должна превзойти указанные бейзлайны (метрика качества - ***accuracy_score***) на тестовой выборке (***df_test***).     \n",
    "Чем больше бейзлайнов вы пройдете, тем выше будет ваша оценка.       \n",
    "Использовать можно любые модели и любые способы получения признаков. \n",
    "\n",
    "+ **!** Необходимо сделать результаты воспроизводимыми (фиксировать random_state)\n",
    "+ **!** Для обучения можно использовать только ***df_train***. \n",
    "+ **!** Менять разбиение на  ***df_train*** и ***df_test*** нельзя.\n",
    "\n",
    "**Оценивание (всего 10 баллов)**: \n",
    "+ Бейзлайн 1 0.73875 - 4 балла\n",
    "+ Бейзлайн 2 0.75325 - 6 баллов\n",
    "+ Бейзлайн 3 0.7635 - 8 баллов \n",
    "+ Бейзлайн 4 0.777 - 10 баллов\n",
    "\n",
    "**Возможные направления улучшения качества**\n",
    "+ улучшение предобработки (сейчас ее по сути нет)\n",
    "+ подбор более удачной модели\n",
    "+ подбор параметров модели \n",
    "+ feature engineering\n",
    "+ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2KrLxz-wZcmp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, hstack\n",
    "from scipy.sparse.csr import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/esolovev/ling2019/master/module2/twi_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Tue Jun 02 02:59:24 PDT 2009</td>\n",
       "      <td>@JackAllTimeLow hope it went good! i couldnt m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Sat Jun 06 00:25:20 PDT 2009</td>\n",
       "      <td>@SDI8732 Idk how to do it!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Fri Jun 05 12:07:23 PDT 2009</td>\n",
       "      <td>@kmwindmill is here ! woop woop , would be bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon Jun 01 14:55:06 PDT 2009</td>\n",
       "      <td>@Daydreamer1984 He explains the tailer better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Sat Jun 20 15:39:44 PDT 2009</td>\n",
       "      <td>still trying to get a pic on this twitter thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Jun 01 17:05:44 PDT 2009</td>\n",
       "      <td>personally, i'm pretty upset ian left the cab....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Fri May 29 15:32:09 PDT 2009</td>\n",
       "      <td>Dance meeting sitting next to deb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Sun May 31 08:07:19 PDT 2009</td>\n",
       "      <td>@thespyglass ha... funnier the way you did it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon Jun 01 18:12:27 PDT 2009</td>\n",
       "      <td>wooh, i love @mileycyruss! i actuallly just sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Sat May 30 09:17:18 PDT 2009</td>\n",
       "      <td>@EdinMarathonBot R-4_it is great  I'm staying ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                          date  \\\n",
       "0       4  Tue Jun 02 02:59:24 PDT 2009   \n",
       "1       0  Sat Jun 06 00:25:20 PDT 2009   \n",
       "2       0  Fri Jun 05 12:07:23 PDT 2009   \n",
       "3       4  Mon Jun 01 14:55:06 PDT 2009   \n",
       "4       0  Sat Jun 20 15:39:44 PDT 2009   \n",
       "5       0  Mon Jun 01 17:05:44 PDT 2009   \n",
       "6       4  Fri May 29 15:32:09 PDT 2009   \n",
       "7       4  Sun May 31 08:07:19 PDT 2009   \n",
       "8       4  Mon Jun 01 18:12:27 PDT 2009   \n",
       "9       4  Sat May 30 09:17:18 PDT 2009   \n",
       "\n",
       "                                                text  \n",
       "0  @JackAllTimeLow hope it went good! i couldnt m...  \n",
       "1                      @SDI8732 Idk how to do it!!!   \n",
       "2  @kmwindmill is here ! woop woop , would be bet...  \n",
       "3     @Daydreamer1984 He explains the tailer better   \n",
       "4  still trying to get a pic on this twitter thin...  \n",
       "5  personally, i'm pretty upset ian left the cab....  \n",
       "6                 Dance meeting sitting next to deb   \n",
       "7  @thespyglass ha... funnier the way you did it...   \n",
       "8  wooh, i love @mileycyruss! i actuallly just sa...  \n",
       "9  @EdinMarathonBot R-4_it is great  I'm staying ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.5\n",
       "0    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# баланс классов\n",
    "df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиение и пропорции обучающей и тестовой выборки менять нельзя\n",
    "SEED = 227\n",
    "np.random.seed(SEED)\n",
    "df_train, df_test = train_test_split(df, train_size=0.2, test_size=0.1, stratify=df.target, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.target\n",
    "y_test = df_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1 \n",
    "Count Vectorizer по словам + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 182 ms, sys: 4.12 ms, total: 186 ms\n",
      "Wall time: 185 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_count = count_vectorizer.fit_transform(df_train.text)\n",
    "X_test_count = count_vectorizer.transform(df_test.text)\n",
    "X_train = X_train_count\n",
    "X_test = X_test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.44 ms, sys: 1.93 ms, total: 6.36 ms\n",
      "Wall time: 7.47 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      2000\n",
      "           4       0.78      0.66      0.72      2000\n",
      "\n",
      "    accuracy                           0.74      4000\n",
      "   macro avg       0.74      0.74      0.74      4000\n",
      "weighted avg       0.74      0.74      0.74      4000\n",
      "\n",
      "Accuracy: 0.73875\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2 \n",
    "TfidfVectorizer по словам + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 ms, sys: 2.65 ms, total: 161 ms\n",
      "Wall time: 161 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(df_train.text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(df_test.text)\n",
    "X_train = X_train_tfidf\n",
    "X_test = X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.2 ms, sys: 3.76 ms, total: 48.9 ms\n",
      "Wall time: 37.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=227, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76      2000\n",
      "           4       0.76      0.74      0.75      2000\n",
      "\n",
      "    accuracy                           0.75      4000\n",
      "   macro avg       0.75      0.75      0.75      4000\n",
      "weighted avg       0.75      0.75      0.75      4000\n",
      "\n",
      "Accuracy: 0.75325\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 3\n",
    "TfidfVectorizer по 1-3 граммам слов + TfidfVectorizer по 3-4граммам символов + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.55 s, sys: 96.9 ms, total: 2.64 s\n",
      "Wall time: 2.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 4))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(df_train.text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(df_test.text)\n",
    "\n",
    "tfidf_vectorizer_char = TfidfVectorizer(ngram_range=(3, 4), analyzer='char')\n",
    "X_train_tfidf_char = tfidf_vectorizer_char.fit_transform(df_train.text)\n",
    "X_test_tfidf_char = tfidf_vectorizer_char.transform(df_test.text)\n",
    "\n",
    "X_train = hstack((X_train_tfidf, X_train_tfidf_char))\n",
    "X_test = hstack((X_test_tfidf, X_test_tfidf_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 475 ms, sys: 23.6 ms, total: 499 ms\n",
      "Wall time: 312 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=227, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      2000\n",
      "           4       0.77      0.76      0.76      2000\n",
      "\n",
      "    accuracy                           0.76      4000\n",
      "   macro avg       0.76      0.76      0.76      4000\n",
      "weighted avg       0.76      0.76      0.76      4000\n",
      "\n",
      "Accuracy: 0.7635\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 4\n",
    "Baseline 3 + эмбединги из spacy (вектор документа = среднее векторов всех его слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.2 s, sys: 533 ms, total: 4.73 s\n",
      "Wall time: 5.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# !python -m spacy download en_core_web_md\n",
    "import spacy \n",
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 774 ms, total: 1min 25s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_vectors = csr_matrix([nlp(twi_text).vector for twi_text in df_train.text])\n",
    "X_test_vectors = csr_matrix([nlp(twi_text).vector for twi_text in df_test.text])\n",
    "X_train = hstack((X_train_tfidf, X_train_tfidf_char, X_train_vectors))\n",
    "X_test = hstack((X_test_tfidf, X_test_tfidf_char, X_test_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.16 s, sys: 53.5 ms, total: 3.21 s\n",
      "Wall time: 1.71 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=227, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      2000\n",
      "           4       0.78      0.76      0.77      2000\n",
      "\n",
      "    accuracy                           0.78      4000\n",
      "   macro avg       0.78      0.78      0.78      4000\n",
      "weighted avg       0.78      0.78      0.78      4000\n",
      "\n",
      "Accuracy: 0.777\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Улучшение препроцессинга только ухудшает результат, поэтому получим ещё один вектор с помощью fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# import nltk\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# from tqdm import tqdm\n",
    "# import jamspell\n",
    "\n",
    "# texts = []\n",
    "# corrector = jamspell.TSpellCorrector()\n",
    "# corrector.LoadLangModel('en.bin')\n",
    "\n",
    "# def normalize(s, sw=False):\n",
    "# #     s = s.replace(\".\", \" \")\n",
    "# #     s = s.replace(\"!\", \" \")\n",
    "# #     s = s.replace(\",\", \" \")\n",
    "#     s = corrector.FixFragment(s)\n",
    "#     #res = word_tokenize(s)\n",
    "    \n",
    "#     #nltk_lem = WordNetLemmatizer()\n",
    "    \n",
    "#     #res = [nltk_lem.lemmatize(i) for i in res]\n",
    "#     res = [i for i in s.split() if len(i) != 0]\n",
    "# #     res = [s.lower() for s in res]\n",
    "#     if len(res) >= 10:\n",
    "#         res = [i for i in res if i not in stopwords.words('english')]\n",
    "# #     res = [s for s in res if s not in string.punctuation]\n",
    "# #     res = [s for s in res if not s.isdigit()]\n",
    "# #     res = [s for s in res if not s.startswith(\"#\")\n",
    "# #            and not s.startswith(\"@\")]\n",
    "\n",
    "#     return \" \".join(res)\n",
    "\n",
    "# # for i in tqdm(df.text.values):\n",
    "# #     texts.append(normalize(i))\n",
    "\n",
    "# #df.text = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = []\n",
    "# for i in tqdm(df_train.text.values):\n",
    "#     texts.append(normalize(i))\n",
    "# df_train.text = texts\n",
    "\n",
    "# texts = []\n",
    "# for i in tqdm(df_test.text.values):\n",
    "#     texts.append(normalize(i))\n",
    "# df_test.text = texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для получения вектора fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import sister\n",
    "sentence_embedding = sister.MeanEmbedding(lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors_fasttext = csr_matrix([sentence_embedding(twi_text)\n",
    "                                       for twi_text in df_train.text.values])\n",
    "X_test_vectors_fasttext = csr_matrix([sentence_embedding(twi_text)\n",
    "                                      for twi_text in df_test.text.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack((X_train_tfidf,\n",
    "                  X_train_tfidf_char,\n",
    "                  X_train_vectors,\n",
    "                  X_train_vectors_fasttext))\n",
    "X_test = hstack((X_test_tfidf,\n",
    "                 X_test_tfidf_char,\n",
    "                 X_test_vectors,\n",
    "                 X_test_vectors_fasttext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получим лучшее значение параметра C (коэффициент регуляризации) с помощью optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:02,742] Finished trial#0 with value: 0.21899999999999997 with parameters: {'C': 1.782387115618453}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:06,163] Finished trial#1 with value: 0.22099999999999997 with parameters: {'C': 2.0378267157026246}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:09,037] Finished trial#2 with value: 0.21999999999999997 with parameters: {'C': 0.9524666587115246}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:13,013] Finished trial#3 with value: 0.21924999999999994 with parameters: {'C': 1.067036804175541}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:17,144] Finished trial#4 with value: 0.21950000000000003 with parameters: {'C': 1.4322331552637195}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:20,606] Finished trial#5 with value: 0.21924999999999994 with parameters: {'C': 1.7402492937265033}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.77875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:24,156] Finished trial#6 with value: 0.22124999999999995 with parameters: {'C': 1.978792365336849}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:26,005] Finished trial#7 with value: 0.22299999999999998 with parameters: {'C': 0.28335090134771834}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.77975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:29,434] Finished trial#8 with value: 0.22024999999999995 with parameters: {'C': 2.236817842314201}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:32,763] Finished trial#9 with value: 0.21924999999999994 with parameters: {'C': 1.7369499442315561}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.77775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:36,287] Finished trial#10 with value: 0.22224999999999995 with parameters: {'C': 2.7807616357065594}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:39,031] Finished trial#11 with value: 0.21999999999999997 with parameters: {'C': 0.9233429406396503}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:42,023] Finished trial#12 with value: 0.21924999999999994 with parameters: {'C': 1.0999929465849911}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:43,849] Finished trial#13 with value: 0.22250000000000003 with parameters: {'C': 0.2914669566643756}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.77825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:47,409] Finished trial#14 with value: 0.22175 with parameters: {'C': 2.5643779903173676}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:50,381] Finished trial#15 with value: 0.21899999999999997 with parameters: {'C': 1.2548699996400567}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:53,394] Finished trial#16 with value: 0.21975 with parameters: {'C': 1.3698862466278863}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:55,648] Finished trial#17 with value: 0.21924999999999994 with parameters: {'C': 0.5904818644530172}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.77975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:05:59,180] Finished trial#18 with value: 0.22024999999999995 with parameters: {'C': 2.375910825737681}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:06:02,471] Finished trial#19 with value: 0.21899999999999997 with parameters: {'C': 1.6118182258536025}. Best is trial#0 with value: 0.21899999999999997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:06:05,084] Finished trial#20 with value: 0.21850000000000003 with parameters: {'C': 0.6503471647683958}. Best is trial#20 with value: 0.21850000000000003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:06:07,767] Finished trial#21 with value: 0.21850000000000003 with parameters: {'C': 0.6566453897319557}. Best is trial#20 with value: 0.21850000000000003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:06:10,359] Finished trial#22 with value: 0.21899999999999997 with parameters: {'C': 0.6082110308816102}. Best is trial#20 with value: 0.21850000000000003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:06:13,097] Finished trial#23 with value: 0.21924999999999994 with parameters: {'C': 0.6369598398202899}. Best is trial#20 with value: 0.21850000000000003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:06:14,919] Finished trial#24 with value: 0.22950000000000004 with parameters: {'C': 0.17260550910092326}. Best is trial#20 with value: 0.21850000000000003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:06:17,674] Finished trial#25 with value: 0.21775 with parameters: {'C': 0.7829608479795515}. Best is trial#25 with value: 0.21775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:06:20,375] Finished trial#26 with value: 0.21775 with parameters: {'C': 0.762256902881218}. Best is trial#25 with value: 0.21775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:06:22,443] Finished trial#27 with value: 0.21924999999999994 with parameters: {'C': 0.4396711641331538}. Best is trial#25 with value: 0.21775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:06:25,187] Finished trial#28 with value: 0.21975 with parameters: {'C': 0.8591896709250502}. Best is trial#25 with value: 0.21775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-06-22 16:06:27,281] Finished trial#29 with value: 0.23750000000000004 with parameters: {'C': 0.11269548079959057}. Best is trial#25 with value: 0.21775.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.7829608479795515}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    C = trial.suggest_float('C', 0.1, 3) \n",
    "    model = LogisticRegression(random_state=SEED,\n",
    "                               C=C,\n",
    "                               solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_pred, y_test)\n",
    "    print(\"acc: \" + str(acc))\n",
    "    return 1 - acc\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем наилучший параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.7829608479795515, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=227, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=SEED,\n",
    "                           C=study.best_params['C'],\n",
    "                           solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79      2000\n",
      "           4       0.79      0.77      0.78      2000\n",
      "\n",
      "    accuracy                           0.78      4000\n",
      "   macro avg       0.78      0.78      0.78      4000\n",
      "weighted avg       0.78      0.78      0.78      4000\n",
      "\n",
      "Accuracy: 0.78225\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### При C=0.7727395412600294 выдаётся Accuracy: 0.78225 (если выше optuna нашла результат хуже, так как не понятно, как в ней фиксировать random_state (и нужно ли...) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.7727395412600294, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=227, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=SEED,\n",
    "                           C=0.7727395412600294,\n",
    "                           solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79      2000\n",
      "           4       0.79      0.77      0.78      2000\n",
      "\n",
      "    accuracy                           0.78      4000\n",
      "   macro avg       0.78      0.78      0.78      4000\n",
      "weighted avg       0.78      0.78      0.78      4000\n",
      "\n",
      "Accuracy: 0.7825\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
