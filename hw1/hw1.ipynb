{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "# Функция возвращает list of dict по каждому фильму\n",
    "def get_films(n: int, time_delay: float) -> list:\n",
    "    if (type(n) is not int) or (type(time_delay) is not float):\n",
    "        raise TypeError('Wrong type in parameters')\n",
    "    if time_delay < 0:\n",
    "        raise ValueError('Time delay should be positive')\n",
    "    if n > 500 or n <= 0:\n",
    "        raise ValueError('Фильмы из топ 500, 0 < n <= 500')\n",
    "    req_n = 0\n",
    "    films_arr = []\n",
    "    if n < 101:\n",
    "        req_n = 1\n",
    "    elif 100 < n < 201:\n",
    "        req_n = 2\n",
    "    elif 200 < n < 301:\n",
    "        req_n = 3\n",
    "    elif 300 < n < 401:\n",
    "        req_n = 4\n",
    "    elif 400 < n < 501:\n",
    "        req_n = 5\n",
    "    count = 0\n",
    "    for i in range(req_n):\n",
    "        time.sleep(time_delay)\n",
    "        adr = 'https://www.kinoafisha.info/rating/movies/?page=' + str(i)\n",
    "        req = requests.request('GET', adr)\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        films = soup.find_all(attrs={'class': \"films_content\"})\n",
    "        for j in range(min(100, n-100*i)):\n",
    "            film = films[j]\n",
    "            name = film.find('a', class_=\"films_name ref\").text\n",
    "            rating = float(film.find('span', class_=\"rating_num\").text)\n",
    "            year = film.find('span', class_=\"films_info\").text.split(', ')[0]\n",
    "            url = 'https://www.kinoafisha.info/' + film.find('a').attrs['href']\n",
    "            _utc_timestamp = str(datetime.datetime.utcnow()).split('.')[0]\n",
    "#             films_arr.append({'name': name,\n",
    "#                                'rating': rating,\n",
    "#                                'year': year,\n",
    "#                                'url': url,\n",
    "#                                '_utc_timestamp': _utc_timestamp})\n",
    "            yield {'name': name,\n",
    "                   'rating': rating,\n",
    "                   'year': year,\n",
    "                   'url': url,\n",
    "                   '_utc_timestamp': _utc_timestamp}\n",
    "    # return films_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'FORD против FERRARI', 'rating': 9.1, 'year': '2019', 'url': 'https://www.kinoafisha.info//movies/8354457/', '_utc_timestamp': '2020-06-22 12:58:58'}\n",
      "{'name': 'Зеленая миля', 'rating': 9.0, 'year': '1999', 'url': 'https://www.kinoafisha.info//movies/4982409/', '_utc_timestamp': '2020-06-22 12:58:58'}\n",
      "{'name': 'Побег из Шоушенка', 'rating': 9.0, 'year': '1994', 'url': 'https://www.kinoafisha.info//movies/7731571/', '_utc_timestamp': '2020-06-22 12:58:58'}\n"
     ]
    }
   ],
   "source": [
    "# выкачиваем данные по 150 фильмам с задержкой 0.7с\n",
    "# films_all = get_films(150, 0.7)\n",
    "films_all = list(get_films(17, 0.7))\n",
    "# отсортируем список по рейтингу фильма\n",
    "films_all = sorted(films_all, key=lambda x: x['rating'], reverse=True)\n",
    "if len(films_all) >= 3:\n",
    "    [print(i) for i in films_all[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular: 2019\n",
      "Year min: 1961\n",
      "Year max: 2020\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# Собираем словарь вида:\n",
    "# \"год выхода фильма -> количество фильмов из топ-500, вышедших в этот год\"\n",
    "y_min = int(films_all[0].get('year'))\n",
    "y_max = int(films_all[0].get('year'))\n",
    "y_popular = int(films_all[0].get('year'))\n",
    "y_popular_c = 0\n",
    "\n",
    "od = {}\n",
    "my_dict = Counter()\n",
    "\n",
    "for film in films_all:\n",
    "    curr_year = int(film.get(\"year\"))\n",
    "    if curr_year < y_min:\n",
    "        y_min = curr_year\n",
    "    elif curr_year > y_max:\n",
    "        y_max = curr_year\n",
    "    if str(curr_year) in my_dict.keys():\n",
    "        my_dict[str(curr_year)] += 1\n",
    "    else:\n",
    "        my_dict[str(curr_year)] = 1\n",
    "    if my_dict[str(curr_year)] > y_popular:\n",
    "        y_popular = curr_year\n",
    "        y_popular_c = my_dict[str(y)]\n",
    "\n",
    "# print(my_dict)\n",
    "\n",
    "# Выводим самый популярный год, а также минимальный и максимальный\n",
    "print('Most popular:', y_popular)\n",
    "print('Year min:', y_min)\n",
    "print('Year max:', y_max)\n",
    "\n",
    "for key, value in od.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from typing import List, Dict, Union, Any\n",
    "\n",
    "\n",
    "def dump_json(film_list: List[Dict[str, Any]], path: str) -> None:\n",
    "\n",
    "    with open(path, 'w', encoding='utf-8') as outfile:\n",
    "        for l in film_list:\n",
    "            json_record = json.dumps(l, ensure_ascii=False)\n",
    "            outfile.write(json_record)\n",
    "\n",
    "\n",
    "def dump_jsonl(film_list: List[Dict[str, Any]], path: str) -> None:\n",
    "\n",
    "    with open(path, 'w', encoding='utf-8') as outfile:\n",
    "        for l in film_list:\n",
    "            print(l)\n",
    "            json_record = json.dumps(l, ensure_ascii=False)\n",
    "            outfile.write(json_record + '\\n')\n",
    "\n",
    "\n",
    "def dump_csv(film_list: List[Dict[str, Any]], path: str) -> None:\n",
    "\n",
    "    with open(path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['name', 'rating', 'year', 'url', '_utc_timestamp']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for l in film_list:\n",
    "            writer.writerow(l)\n",
    "\n",
    "\n",
    "def dump_tsv(film_list: List[Dict[str, Any]], path: str) -> None:\n",
    "\n",
    "    with open(path, 'wt', encoding='utf-8') as tsvfile:\n",
    "        fieldnames = ['name', 'rating', 'year', 'url', '_utc_timestamp']\n",
    "        tsv_writer = csv.DictWriter(tsvfile,\n",
    "                                    fieldnames=fieldnames,\n",
    "                                    delimiter='\\t')\n",
    "\n",
    "        for l in film_list:\n",
    "            tsv_writer.writerow(l)\n",
    "\n",
    "\n",
    "# Записываем данные в файлы\n",
    "# Функция должна иметь следующую сигнатуру (набор и тип аргументов)\n",
    "def dump(film_list: List[Dict[str, Any]],\n",
    "         path: str,\n",
    "         filetype: str,\n",
    "         order_by: str,  # поле словарей, по которому будем сортировать\n",
    "         ascending: bool) -> None:\n",
    "    if filetype not in ['json', 'jsonl', 'csv', 'tsv']:\n",
    "        raise TypeError('Wrong filetype in parameters')\n",
    "    if order_by not in ['name', 'rating', 'year', 'url', '_utc_timestamp']:\n",
    "        raise TypeError('Wrong order_by in parameters')\n",
    "    rvrs = not ascending\n",
    "    # сортируем по выбранному полю\n",
    "    films_sorted = sorted(film_list, key=lambda i: i[order_by], reverse=rvrs)\n",
    "    if filetype is 'json':\n",
    "        dump_json(films_sorted, path)\n",
    "    elif filetype is 'jsonl':\n",
    "        dump_jsonl(films_sorted, path)\n",
    "    elif filetype is 'csv':\n",
    "        dump_csv(films_sorted, path)\n",
    "    elif filetype is 'tsv':\n",
    "        dump_tsv(films_sorted, path)\n",
    "\n",
    "\n",
    "# Записываем tab-separated файл, отсортированный по убыванию времени выгрузки.\n",
    "dump(films_all,\n",
    "     r\"myfile.json\",\n",
    "     filetype='json',\n",
    "     order_by='rating',\n",
    "     ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40.221.83.211'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randrange\n",
    "# Class A 1.0.0.1 to 126.255.255.254\n",
    "# Class B 128.1.0.1 to 191.255.255.254\n",
    "# Class C 192.0.1.1 to 223.255.254.254\n",
    "\n",
    "MAX_VAL = 255\n",
    "\n",
    "\n",
    "def random_ip() -> str:\n",
    "    p1 = randrange(0, MAX_VAL)\n",
    "    p2 = randrange(0, MAX_VAL)\n",
    "    p3 = randrange(0, MAX_VAL)\n",
    "    p4 = randrange(0, MAX_VAL)\n",
    "    ip = str(p1)+'.'+str(p2)+'.'+str(p3)+'.'+str(p4)\n",
    "    return ip\n",
    "\n",
    "\n",
    "random_ip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from random import uniform\n",
    "\n",
    "list_time_zones = []\n",
    "\n",
    "\n",
    "def ip_list_to_json(local_list: List[str],\n",
    "                    path: str):\n",
    "    with open(path, 'w', encoding='utf-8') as outfile:\n",
    "        for l in local_list:\n",
    "            url = \"https://freegeoip.app/json/\" + l\n",
    "            headers = {\n",
    "                'accept': \"application/json\",\n",
    "                'content-type': \"application/json\"\n",
    "            }\n",
    "            response = requests.request(\"GET\", url, headers=headers)\n",
    "            ip_dict = response.json()\n",
    "            ip_str = response.text\n",
    "            tz = ip_dict.get('time_zone')\n",
    "            if len(tz) > 0 and tz not in list_time_zones:\n",
    "                list_time_zones.append(tz)\n",
    "\n",
    "            # print(tz)\n",
    "            json_record = json.dumps(ip_str, ensure_ascii=False)\n",
    "            # print(ip_str)\n",
    "\n",
    "            outfile.write(ip_str)\n",
    "            time.sleep(uniform(0.5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_list = []\n",
    "\n",
    "for i in range(100):\n",
    "    ip = random_ip()\n",
    "    while ip in ip_list:\n",
    "        ip = random_ip()\n",
    "    ip_list.append(ip)\n",
    "\n",
    "ip_list_to_json(ip_list, r'ip_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "America/Chicago\n",
      "2019-03-04 08:12:05\n",
      "\n",
      "Asia/Riyadh\n",
      "2019-03-04 17:12:05\n",
      "\n",
      "Europe/Berlin\n",
      "2019-03-04 15:12:05\n",
      "\n",
      "Asia/Shanghai\n",
      "2019-03-04 22:12:05\n",
      "\n",
      "America/New_York\n",
      "2019-03-04 09:12:05\n",
      "\n",
      "Asia/Nicosia\n",
      "2019-03-04 16:12:05\n",
      "\n",
      "Europe/London\n",
      "2019-03-04 14:12:05\n",
      "\n",
      "Europe/Helsinki\n",
      "2019-03-04 16:12:05\n",
      "\n",
      "Asia/Tokyo\n",
      "2019-03-04 23:12:05\n",
      "\n",
      "America/Santiago\n",
      "2019-03-04 11:12:05\n",
      "\n",
      "Asia/Seoul\n",
      "2019-03-04 23:12:05\n",
      "\n",
      "Europe/Oslo\n",
      "2019-03-04 15:12:05\n",
      "\n",
      "America/Sao_Paulo\n",
      "2019-03-04 11:12:05\n",
      "\n",
      "Europe/Istanbul\n",
      "2019-03-04 17:12:05\n",
      "\n",
      "Europe/Budapest\n",
      "2019-03-04 15:12:05\n",
      "\n",
      "Australia/Sydney\n",
      "2019-03-05 01:12:05\n",
      "\n",
      "America/Phoenix\n",
      "2019-03-04 07:12:05\n",
      "\n",
      "Europe/Bratislava\n",
      "2019-03-04 15:12:05\n",
      "\n",
      "Europe/Paris\n",
      "2019-03-04 15:12:05\n",
      "\n",
      "Africa/Cairo\n",
      "2019-03-04 16:12:05\n",
      "\n",
      "Europe/Stockholm\n",
      "2019-03-04 15:12:05\n",
      "\n",
      "America/Denver\n",
      "2019-03-04 07:12:05\n",
      "\n",
      "Europe/Lisbon\n",
      "2019-03-04 14:12:05\n",
      "\n",
      "Europe/Moscow\n",
      "2019-03-04 17:12:05\n",
      "\n",
      "Asia/Taipei\n",
      "2019-03-04 22:12:05\n",
      "\n",
      "Europe/Madrid\n",
      "2019-03-04 15:12:05\n",
      "\n",
      "Europe/Amsterdam\n",
      "2019-03-04 15:12:05\n",
      "\n",
      "America/Los_Angeles\n",
      "2019-03-04 06:12:05\n",
      "\n",
      "America/Lima\n",
      "2019-03-04 09:12:05\n",
      "\n",
      "America/Mexico_City\n",
      "2019-03-04 08:12:05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "# random time moment in 2019\n",
    "random_moment = randrange(1546300800, 1577836799)\n",
    "d_local = datetime.datetime.utcfromtimestamp(random_moment).isoformat()\n",
    "\n",
    "timestring = d_local\n",
    "d = datetime.datetime.strptime(d_local, \"%Y-%m-%dT%H:%M:%S\")\n",
    "d = pytz.timezone('UTC').localize(d)\n",
    "\n",
    "for tz_local in list_time_zones:\n",
    "    d = d.astimezone(pytz.timezone(tz_local))\n",
    "    print(d.tzinfo) # Return time zone info\n",
    "    print(d.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
